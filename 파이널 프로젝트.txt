파이널 프로젝트 업무

1. controller에서 log4j로 로그파일 캡쳐한뒤 apache flume으로 hdfs 클러스터에 저장
	진행상황 : -기업/뉴스/채용공고/스크랩북 이벤트 발생시 로그데이터 적재 루틴 구현 완료
		    -기업/뉴스/채용/스크랩북의 관심버튼을 누르는 이벤트 발생시 유저 로그 수집 작업중
			-스크랩북 작성에 참고한 기사 url 수집 미완
			-apache flume으로 로그파일 적재폴더 주시설정 한 뒤 클러스터에 적재 미완

2. 로그 데이터 분석하여 사용자의 행동로그 기반으로 추천기업을 서비스하기
	진행상황 : -샘플 데이터를 통해 random forest 테스트 완료
			-sklearn 패키지를 통해 실제 모델 구현 완료
			-구현된 모델의 정확성 출력 완료
			-모델에 변수가 입력되었을때 결과값 샘플 출력 진행중
			-회원가입시 기재하였던 연령, 학력등의 정보가 담긴 dataframe 구축 미완
			-사용자가 열람한 뉴스들의 카테고리가 담긴 dataframe 구축 미완
			-전체 사용자들이 많이 노출된 상위 500개 단어에 노출된 횟수가 담긴 dataframe 구축 미완
	추가	  : -flume으로 로그를 적재한 정보를 스트리밍으로 바로 분석시킬 수 있도록		

3. 웹상의 비정형 뉴스데이터를 수집해 mongoserver에 적재
	진행상황 : -뉴스 데이터를 수집해 mongodb에 입력한뒤 시퀀스 업데이트 루틴 구현 환료
			

4. mongoserver에 적재된 뉴스 데이터를 전처리한뒤 분석하여 dataframe, csv 형태로 저장
	진행상황 : -mongodb 입력 데이터를 인출해 전처리한뒤 명사들을 추출해 MAP-REDUCE 하여 dataframe 만들기 완료
			-mr된 dataframe을 통하여 단어-단어간 관계 테이블, 문서-문서간 관계 테이블 샘플 구성 테스트 완료 --> 구성 시작
			-hadoop cluster에 있는 기존 dataframe 과 병합하여 전체 분석 데이터 담긴 테이블 구성하기 미완 --> 테스트 완료
			
5. tomcat web server에서 입력된 검색어를 기준으로 문서 정렬해서 서비스하기
	진행상황 : -검색 단어를 입력받아 hdfs 내부의 단어 - 단어간 테이블을 조회한뒤 뉴스 문서 스코어링 함수 만들기 의사코드로 구현중 미완
			-정렬된 뉴스 문서들의 번호중 상위 n개를 추출해 문서-문서간 테이블을 조회하여 유사도가 일정수치 이상인것을 
			제거하는 코드 작성 의사코드로 구현중 미완 

6. 구현된 플랫폼과 기존 웹 서비스 병합 - 전체 미완
	진행상황 : -기존 URL을 기준으로 인출하던 뉴스를 news_number 필드 기준으로 변경
			-oracle에 적재하던 api 정보들을 mongodb로 대체
			-5번 코드를 spring project에 결합
			-분석된 로그 데이터 출력해줄 디자인 지정
			-...